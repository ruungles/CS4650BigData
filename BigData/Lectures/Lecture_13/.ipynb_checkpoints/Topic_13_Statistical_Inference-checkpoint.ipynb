{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923b1921",
   "metadata": {},
   "source": [
    "# Topic 13: Statistical Inference\n",
    "\n",
    "With _Statistical Inference_, we infer predictions about the population based on measurements of the sample.  The underlying assumption is that there are some parameters of the population of which we do not have direct knowledge.  We can, however, compute parameter values from the sample.  How then can we relate the sample parameters to the population parameters?\n",
    "\n",
    "There are two schools of thought about how to do this.  In fact, there is a bit of a war on the internet between these two approaches.  However, try to find a clear description of these approaches!  These approaches are the _frequentist_ and the _Bayesian_.\n",
    "\n",
    "* Frequentist: The population has some parameters that are fixed, but are unaccessible to the observer.  But we can take samples from the population, then compute the parameters from the sample.  We can then use statistical inference techniques to make probable propositions regarding the population parameters.\n",
    "\n",
    "* Bayesian: The data is fixed, the result of a sampling process.  But performing another sample will result in different, but fixed, data.  Parameters describing the data can be described probabilistically.  Bayesian inference methods produce parameter distributions.\n",
    "\n",
    "The book summarizes these statements in this way:\n",
    "\n",
    "* The assumptions in the Frequentist approach are related to the sampling process.\n",
    "\n",
    "* The assumptions in the Bayesian approach are related to the statistical model.\n",
    "\n",
    "To dig deeper into this is beyond the scope of this class!  The examples from the book are from the Frequentist approach, but the book recommends that the reader explores the Bayesian approach!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b09cc",
   "metadata": {},
   "source": [
    "## Statistical Inference: The Frequentist Approach\n",
    "\n",
    "The objective of Statistical Inference using the Frequentist approach is to produce probable propositions concerning population parameters from an analysis of a sample.  The following are the most important classes of propositions:\n",
    "\n",
    "* Propositions about _point estimates_.  A point estimate is a value that approximates some parameter of interest, such as the mean or variance of the sample.\n",
    "\n",
    "* Propositions about _confidence intervals_ or _set estimates_.  A confidence interval is a range of values that best represents some parameter of interest.\n",
    "\n",
    "* Propositions about the acceptance or rejection of a _hypothesis_.\n",
    "\n",
    "This process is based on the assumption that we can estimate the probability that the result has been caused by chance.\n",
    "\n",
    "Traditional statistics was developed before the advent of electronic computers, so the tedious computations had to be performed by hand.  Consequently, these techniques were weveloped using theoretical approximations, idealized models and assumptions, and were focused on measuring the effects of chance on the statistic of interest.\n",
    "\n",
    "With modern computers, alternative strategies became available, and more realistic models can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0e75c",
   "metadata": {},
   "source": [
    "## Preparing the Notebook\n",
    "\n",
    "The following is the standard practice of loading the modules required for the Notebook.\n",
    "\n",
    "In addition to the usual suspects, we also load the math package, so we can access the square root function.\n",
    "\n",
    "The book also took this opportunity to initialize some of the plotting parameters.  But I didn't do this, as I didn't have Latex installed on my computer, and maybe you don't as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb628094",
   "metadata": {},
   "source": [
    "## Estimates and Their Validity\n",
    "\n",
    "Because we are not working on the whole population, we cannot get completely accurate values for the statistics.  And actually, even if we could sample the complete population, there may be variability in each entity's response, so collecting a second set of measures might not return exactly the same results.  So we know the results of descriptive statistics is not the _truth_, but is an approximation of the truth.  The assumption is that as we increase the size of the sample, the results approach the truth.\n",
    "\n",
    "An important part of these statistics is to be able to measure the variability of the results:  How closely do we expect the results to approximate the value for the whole population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a772c5b",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "For this topic, we will be using a dataset of traffic accidents occurring in Barcelona in 2013 (and at one point we will also consider 2010 data).  Each event in the dataset represents key values concerning an accident, such as the day, time, address, number of dead and injured people, and so on.\n",
    "\n",
    "This dataset has 9457 records, and will represent the complete population.  Since this is the complete population, we can compute the exact values for various metrics (we will consider this the _truth_).\n",
    "\n",
    "However, for most of the work we will be doing, we will select a subset of this entire set, to be a sample under consideration.  We can then compute the metrics for this sample, then compare the results from the sample with the results from the population.  In fact, in many cases, we will select many samples, so we can see the distribution of the results obtained by these computations.\n",
    "\n",
    "Most of our work will be considering the daily number of traffic accidents.  So after we collect and prepare the data, we will be summarizing the data as the number of accidents occurring each day.\n",
    "\n",
    "The two data files we will be using are in the zip file for this lecture on Canvas.\n",
    "\n",
    "Let's first load the 2013 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd88a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ACCIDENTS_GU_BCN_2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046bc62",
   "metadata": {},
   "source": [
    "We can take an initial peek at the data.  We can ask for the shape of the data, we can run .describe(), we can see the list of column names.  I like just printing the array itself, so we can see the first few and last few rows.  We can see some typical values and what format they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60faaae",
   "metadata": {},
   "source": [
    "This data is coming from Barcelona, so this is probably either Spanish or Catalan.  Interestingly, the majority of people in Barcelona speak both Spanish and Catalan, but these two languages are mutually unintelligible.  Luckily we are only going to be looking at the dates of the accidents.\n",
    "\n",
    "But I don't see any columns that look like dates.  Just like many rows have been masked (using ...), we can also see that some columns have been dropped.  So let's look at the list of column names to see if any of these might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295c3b4",
   "metadata": {},
   "source": [
    "Looking through this list, we can see 'Mes de any', which might just be 'Month of year', 'Nom mes', which might be the name of the month, and 'Dia de mes', which might be the day of the month.  Let's look at some sample values from these columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Mes de any', 'Nom mes', 'Dia de mes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6cf71",
   "metadata": {},
   "source": [
    "This looks very promising.  The fact that the book tells us to use these columns is also a big clue!\n",
    "\n",
    "We are going to be grouping the data by date, so somehow we need to make a column that has dates in it.\n",
    "\n",
    "We can build a date by concatenating the month (the numeric version) with the day of the month, but then we also need to add in the year.  The year for this data is 2013.\n",
    "\n",
    "This is easier said than done.  We might be tempted to do something like this:\n",
    "\n",
    "  data['Date'] = '2013-' + data['Mes de any'] + '-' + data['Dia de mes']\n",
    "\n",
    "You may ask what we are intending to do here!  data['Date'] indicates that we are trying to create a new column (Series) in the DataFrame.  On the right-hand side, we have a mixture of constant string values ('2013-' and '-') and Series values (data['Mes de any'] and data['Dia de mes']), and we are trying to concatenate these values.  The code is trying to combine Series and constants.  What this does is to examine each row at a time, performing the calculations on each row of data.  In essence, it turns this into a loop:\n",
    "\n",
    "* for i in range(data.size()):\n",
    "* _ _ data['Date'][i] = '2013-' + data['Mes de any'][i] + '-' + data['Dia de mes'][i]\n",
    "    \n",
    "That was pseudocode, but you can see how this assignment expands into a loop.\n",
    "\n",
    "The data in these two columns are integer values, and python does not allow us to directly concatenate strings and integers.\n",
    "\n",
    "I tried various operations without success, trying to convert those integers to strings.  So then I looked to see how the book did in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069abf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = '2013-' + data[u'Mes de any'].apply(lambda x: str(x)) + '-' + data[u'Dia de mes'].apply(lambda x: str(x))\n",
    "data.Date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bba86",
   "metadata": {},
   "source": [
    "So we wrote a lambda function which converts an integer to a string (using the str() function).  \n",
    "\n",
    "Also note that for the names of the columns, the strings are prefixed with a 'u' character.  This indicates the string is unicode.  As we can see from some of the listings above, the data does have unicode characters, so to make sure the string comparisons work, we build the column names as unicode as well.\n",
    "\n",
    "_Actually, these particular column names did not have any non-ASCII characters, so we didn't need to use the 'u' prefix.  I even tried, it does work to remove the u.  But it is good practice to put the u's in.  If we later change which columns we are looking at, we might forget to put the u back in._\n",
    "\n",
    "One last thing...the type of data in this column is _object_.  We have what looks like legal dateTime values, but they are just strings.  Luckily Pandas has a function that can convert a Series of strings into a Series of dateTime values.  We use the following code to replace the string version of the column with a dateTime version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.Date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b386c0",
   "metadata": {},
   "source": [
    "Now we are getting really close!  We have a column that holds the dates, so we can group by that.  When we do the groupby, we then want to reduce the data (combine all of the rows in the group to a single row containing a summary metric).  Since we just want the number of accidents each day, we can simply ask for the size of the group.  We will store the results of the grouping/reduction in a new Series, _accidents_.  We will still have our original dataset, but now we have a new Series containing just the data we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48785d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents = data.groupby(['Date']).size()\n",
    "accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15edb2f",
   "metadata": {},
   "source": [
    "As we would expect, there are 365 rows in the set, as there is one row for each day in the year.  And we also see that each row only contains a single cell holding an integer, the number of accidents on that day.  We can print out the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accidents.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b354199",
   "metadata": {},
   "source": [
    "We are just about to get started with our analysis...but the data is in a Series.  That is somewhat great, but DataFrames are more useful.  Luckily Pandas has a function that creates a DataFrame from a Series.  (The original Series is still intact, but we now have a DataFrame version).\n",
    "\n",
    "While we are at it, we can give a name to the column, rather that leave the name as the default '1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = accidents.to_frame()\n",
    "df.columns = ['Count']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474512f",
   "metadata": {},
   "source": [
    "Perhaps we should plot the data, to give us an idea of what we are looking at.  Perhaps some things will pop out of the graph.  Here is a simple graph of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "plt.ylabel('Number of accidents')\n",
    "plt.xlabel('Day')\n",
    "plt.plot(np.array(accidents), 'b+', lw=0.7, alpha=0.7)\n",
    "plt.plot([accidents.mean()]*365, 'r', lw=0.7, alpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92828b00",
   "metadata": {},
   "source": [
    "We can see that the data is pretty evenly spread out, between about 10 and 50 accidents per day.\n",
    "\n",
    "Before we move on, let's look at the code for generating this plot:\n",
    "\n",
    "* The book usually started all graphs with this line.  As I understand, the 'fig' and 'ax' are two portions of the plot, the actual figure and the part that draws the axes.  By setting the figsize, this sets the size of the image on the page.  Adjust these values to get the image to appear the size you want in the Notebook.\n",
    "\n",
    "* plt.ylabel, plt.xlabel, plt.title set the labels for the axes and for the diagram as a whole.  For this chart, they didn't include a title.\n",
    "\n",
    "* Next are two plots.  The first plots the data points, the second draws the mean of the values (the red line in the diagram).\n",
    "\n",
    "* For each plot, we give an array of values.  In the first plot, these are the actual data points.  In the second plot, we take the data's mean, then replicate that 365 times to make an array of the same size, but will identical values in all spots.\n",
    "\n",
    "* The next string indicates how to draw the data.  The first character, 'b' or 'r', set the color of the lines (blue or red).  For the first plot, the '+' character indicates what to draw for each point on the plot (in this case plus symbols).\n",
    "\n",
    "* The 'lw' parameter sets the line width.  There is no actual line for the first plot, but for the second plot, there is a line.\n",
    "\n",
    "* Finally, the 'alpha' value sets the transparency of the color.\n",
    "\n",
    "What follow is a different version of the plot.  In this case, the format string is 'b-+'. The 'b' sets the color to blue, the '-' indicates that a line should be drawn between each of the points, and the '+' indicates what should be drawn at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "plt.ylabel('Number of accidents')\n",
    "plt.xlabel('Day')\n",
    "plt.plot(np.array(accidents), 'b-+', lw=0.7, alpha=0.7)\n",
    "plt.plot([accidents.mean()]*365, 'r', lw=0.7, alpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4306f",
   "metadata": {},
   "source": [
    "Excellent, we are now ready to get started.\n",
    "\n",
    "## Samples\n",
    "\n",
    "As we stated earlier, we typically work with _samples_ rather than with the whole _population_.  Our population is the _df_ DataFrame, these 365 rows of data.  We can select some of the elements from this DataFrame to make a new DataFrame with fewer values.\n",
    "\n",
    "Once we have done that, we can compute some metric for the sample, then we can compare that to the same metric computed for the whole population.\n",
    "\n",
    "For example, one really simple and useful metric is the mean.  And we have already computed the mean for the population, it was about 25.9.  So let's build a sample, then compute it's mean.\n",
    "\n",
    "A DataFrame has a method for selecting a random sample.  The name of the method is 'sample', and one of the parameters we can pass to this method is 'n', the number of elements to select for our sample.\n",
    "\n",
    "Clearly we can't select _all_ of the values (and we can't select _more_ than the number of values in the population).  On the other hand, we also don't want to select too few, because then maybe our subset is not really representative.\n",
    "\n",
    "We will experiment with the size in a bit, but for now, let's use a sample size of 200:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20996dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled1 = df.sample(n = 200)\n",
    "sampled1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a51f8",
   "metadata": {},
   "source": [
    "This looks like a reasonable sample, and the rows even appear to be in a random order.  We can compute the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf9489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e0c1e9",
   "metadata": {},
   "source": [
    "OK, so the mean for our sample is not the same as the mean for the whole population.  It is pretty close, but not exact.  And we wouldn't expect an exact match.  Let's try a couple more examples.  We will make some new samples and check their means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled2 = df.sample(n = 200)\n",
    "sampled2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled3 = df.sample(n = 200)\n",
    "sampled3.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b192c607",
   "metadata": {},
   "source": [
    "So the means for each of the samples are different, but they are all fairly close to the population mean.  If we rerun this Notebook, we will get different answers!  And if you run this at home, you will get different answers as well, because the samples are randomly generated.\n",
    "\n",
    "How does this help us?  Yes, we are looking at samples, but how can we determine the population mean when the sample means vary?\n",
    "\n",
    "We only have a few datapoints here.  What if we run a _lot_ of samples, then look at the distribution of the means that we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046413b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trySamples(num_test, num_elements, num_bins):\n",
    "    means = []\n",
    "    for i in range(num_test):\n",
    "        rows = df.sample(n = num_elements)\n",
    "        means.append(rows.mean()[0])\n",
    "    s = pd.Series(means)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 3))\n",
    "    s.hist(histtype = 'stepfilled', bins = num_bins)\n",
    "    ax.axvline(x=accidents.mean(), ymin=0, ymax=40, color=[1, 0, 0])\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Mean number of accidents')\n",
    "    plt.title(f'Sampling distribution of the sample mean (samples: {num_test}, size: {num_elements}, bins: {num_bins})')\n",
    "    \n",
    "trySamples(10000, 200, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd14c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled1.sort_values(by = 'Count', ascending = True, inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1f211",
   "metadata": {},
   "source": [
    "We can see that the sample mean follows a normal distribution around the population's mean.\n",
    "\n",
    "We have three parameters to this function: The number of samples run, the number of elements in each sample, and the number of bins in the histogram.  How did we choose these values?  Let's try varying these values to see what happens.\n",
    "\n",
    "First, let's try lowering the number of samples run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d390c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trySamples(1000, 200, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5116c",
   "metadata": {},
   "source": [
    "While we can vaguely see the shape of a normal distribution, its not too clear.  There is a tradeoff: with fewer trials, the shape of the curve gets very chunky, but with more trials, it takes longer to generate the results.\n",
    "\n",
    "Now let's try fewer elements in each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88930b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trySamples(10000, 50, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trySamples(10000, 20, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c39bc",
   "metadata": {},
   "source": [
    "While the general shape of the distribution stays about the same, the variance increases greatly!\n",
    "\n",
    "* With 200 elements, the lower tail of the curve was close to 25.\n",
    "\n",
    "* With 50 elements, the lower tail was about 23.\n",
    "\n",
    "* With 20 elements, the lower tail was about 21.\n",
    "\n",
    "We can't really try _more_ elements, since the complete population is only 365!\n",
    "\n",
    "I am rather curious:  What if the size of the population was one million?  Would 200 elements still be a reasonable sample size, or would we need to have a substantially larger sample size?\n",
    "\n",
    "The next thing to vary is the number of bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trySamples(10000, 200, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trySamples(10000, 200, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc5fc6",
   "metadata": {},
   "source": [
    "If we have too many bins, we see a lot more granularity.  If we have too few bins, then we lose a lot of detail.\n",
    "\n",
    "When performing an analysis, some times we need to explore a bit to find the parameters that give us the most information.  Care must be taken not to search for a view that best fits our preconceived ideas or that best matches our desired outcome.  We want to find the view that best describes the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c607a",
   "metadata": {},
   "source": [
    "## Empirical Standard Error\n",
    "\n",
    "One interesting metric is, \"What is the standard deviation of the sample mean?\"  We have seen that the sample means vary from the population mean, but by how much do these samples vary?  If the standard deviation is small, then our sample mean is probably fairly close to the population mean.  But if the standard deviation is large, then we are less sure about our estimate reflecting the population's value.\n",
    "\n",
    "It can be mathematically shown that given _n_ independent observations (in other words, if we have a sample of _n_ elements) of a population with a standard deviation $ \\sigma_x $, the standard error $ \\sigma_{\\bar x} $ can be approximated by:\n",
    "\n",
    "$$ S E = \\frac{\\sigma_x}{\\sqrt n} $$\n",
    "\n",
    "This result is based on the Central Limit Theorem, an old theorem introduced in 1810 by Laplace.\n",
    "\n",
    "This formula uses the standard deviation of the population $ \\sigma_x $, which is not known, but it can be shown thatif it is substituted by its empirical estimate $ \\hat \\sigma_x $, the estimation is sufficiently good if $ n > 30 $ and the population distribution is not skewed.\n",
    "\n",
    "So how do we measure the variability of the sample mean?  By giving the _empirical standard error of the mean distribution_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardError(num_test, num_elements):\n",
    "    rows = df.sample(n = num_elements)\n",
    "    est_sigma_mean = rows.std() / math.sqrt(num_elements)\n",
    "    means = []\n",
    "    for i in range(num_test):\n",
    "        srows = df.sample(n = num_elements)\n",
    "        means.append(srows.mean())\n",
    "    sim_mean = pd.Series(means).std()\n",
    "    print(f'Direct estimation of SE from one sample of {num_elements} elements: {est_sigma_mean[0]}')\n",
    "    print(f'Estimation of the SE by simulating {num_test} samples of {num_elements}: {sim_mean}')\n",
    "\n",
    "standardError(10000, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4bf41",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9b90b",
   "metadata": {},
   "source": [
    "In our previous examples, we considered the dataset to be the whole population, then we picked a sample from this set to compute the mean.  However, we could not determine the distribution of the mean since we only had one value.\n",
    "\n",
    "To fix this problem, we created many samples from the dataset, computed each of the means, then we could examine the distribution of these means.  From that, we determined the variance of the means.\n",
    "\n",
    "What if the was not the whole population, but rather a sample of the whole population.  If this is the case, then we only have the one sample, and we cannot construct any other samples of the population.  So how do we determine the variance?\n",
    "\n",
    "One technique is called _bootstrapping_.  We make a series of samples _of our original sample_.  We can then approximate the variance of the original sample (our dataset), and thereby we have an approximation of the variance for the whole population!\n",
    "\n",
    "To summarize:\n",
    "\n",
    "* There is the population, which we don't have access to.\n",
    "\n",
    "* We do have one sample from the population, which is our dataset.\n",
    "\n",
    "* We make a smaller sample from the dataset, and compute the mean of that.\n",
    "\n",
    "* We repeat that last step many times, and can then compute the variance of the dataset.\n",
    "\n",
    "* The variance of the dataset is a good approximation of the variance we would find for the whole population, if we were to gain access to the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanBootstrap(data, iterations):\n",
    "    means = []\n",
    "    for i in range(iterations):\n",
    "        sample = [data[j] for j in np.random.randint(len(data), size=len(data))]\n",
    "        means.append(np.mean(sample))\n",
    "    return pd.Series(means)\n",
    "\n",
    "m = meanBootstrap(accidents, 10000)\n",
    "print(\"Mean estimate: \", m.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.hist(histtype='stepfilled', bins = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdbc719",
   "metadata": {},
   "source": [
    "## Confidence Interval\n",
    "\n",
    "A point estimate $ \\Theta $, such as the sample mean, provides a _plausible value_ for a parameter.  This does not perfectly match the actual value, but should be reasonably close.\n",
    "\n",
    "We would like to model how much this estimation might vary from the actual value.  Computing the standard error is one way to express this variability.\n",
    "\n",
    "Another approach would be to provide a _plausible range of values_ for the parameter.  In other words, we might say that we expect the actual value to be somewhere in the range $ \\alpha < x < \\beta $.  This plausible range is called a _confidence interval_.\n",
    "\n",
    "However, there can be many _confidence intervals_, each with a different _degree of confidence_.  For example, we might say:\n",
    "\n",
    "* We are 90% certain that the actual value is in the interval from 25.1 to 26.7.\n",
    "\n",
    "* We are 95% certain that the actual value is in the interval from 24.98 to 26.84.\n",
    "\n",
    "* We are 99% certain that the actual value is in the interval from 24.68 to 27.14.\n",
    "\n",
    "We construct a confidence interval as follows:\n",
    "\n",
    "* The point estimate ($ \\Theta $) is the most plausible value for the parameter.  We use this as the center of the confidence interval.\n",
    "\n",
    "* The spread of the confidence interval should be related to the sampling distribution of the estimate.\n",
    "\n",
    "* For example, using a spread of 1.96 _SE_ from $ \\Theta $, we are saying that we are 95% certain that the true parameter value is in this range.  Reflecting this, we are also saying that there is a 95% chance that $ \\Theta $ is within this distance from the true value!\n",
    "\n",
    "For the case of the mean, the Central Limit Theorem states that its sampling distribution is normal:\n",
    "\n",
    "__Theorem__ _Given a population with a finite mean $ \\mu $ and a finite non-zero variance $ \\sigma^2 $, the sampling distribution of the mean approaches a normal distribution with a mean of $ \\mu $ and a variance of $ \\frac{\\sigma^2}{n} $ as n, the sample size, increases._\n",
    "\n",
    "We make use of a well-known result from probability that appies to normal distributions: roughly 95% of the time our estimate will be within 1.96 standard errors of the true mean.  Given an interval that spreads out 1.96 standard errors, we can say that we are _roughly 95% confident that the range captures the true parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20629aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidenceInterval(data, level):\n",
    "    match level:\n",
    "        case 90:\n",
    "            factor = 1.65\n",
    "        case 95:\n",
    "            factor = 1.96\n",
    "        case 99:\n",
    "            factor = 2.58\n",
    "        case 99.9:\n",
    "            factor = 3.291\n",
    "        case _:\n",
    "            factor = 1.96\n",
    "    m = data.mean()\n",
    "    se = data.std() / math.sqrt(len(data))\n",
    "    return [m - se * factor, m + se * factor]\n",
    "\n",
    "print(f'Confidence interval: {confidenceInterval(accidents, 95)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb336259",
   "metadata": {},
   "source": [
    "A spread of 1.96 _SE_ gives us 95% confidence.  You can see in the above code several other spreads and their associated confidence levels.\n",
    "\n",
    "We can use bootstrapping to compute a confidence interval of the sample mean as follows:\n",
    "\n",
    "* For a large number of times, _s_, select a bootstrap sample from the dataset then compute the mean of this bootstrap sample.\n",
    "\n",
    "* Compute the mean of the _s_ means to get the bootstrapped estimate of the sample mean.\n",
    "\n",
    "* Calculate the standard deviation of that set of _s_ values, giving the bootstrapped estimate of the standard error (_SE_).\n",
    "\n",
    "* Obtain the 2.5th and 97.5th percentiles of the _s_ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de849250",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = meanBootstrap(accidents, 10000)\n",
    "sample_mean = m.mean()\n",
    "sample_se = m.std()\n",
    "print(f'Mean estimate: {sample_mean:.4f}')\n",
    "print(f'SE of the estimate: {sample_se:.4f}')\n",
    "ci = [np.percentile(m, 2.5), np.percentile(m, 97.5)]\n",
    "print(f'Confidence interval: {ci}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfce8c7",
   "metadata": {},
   "source": [
    "## But What Does \"95% Confident\" Mean?\n",
    "\n",
    "Suppose we took many samples from a population and built a 95% confidence interval from each of the samples.  Then about 95% of those intervals would contain the actual parameter.\n",
    "\n",
    "The following cell shows this procedure for 100 samples (we could use more samples, but the plot would lose detail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfabe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = accidents   \n",
    "\n",
    "n = 100                                               # number of observations\n",
    "N_test = 100                                          # number of samples with n observations\n",
    "means = np.array([0.0] * N_test)                      # samples' mean\n",
    "s = np.array([0.0] * N_test)                          # samples' std\n",
    "ci = np.array([[0.0,0.0]] * N_test)\n",
    "tm = df.mean()                                        # \"true\" mean\n",
    "\n",
    "for i in range(N_test):                               # sample generation and CI computation\n",
    "    rows = np.random.choice(df.index.values, n)\n",
    "    sampled_df = df.loc[rows]\n",
    "    means[i] = sampled_df.mean()\n",
    "    s[i] = sampled_df.std()\n",
    "    ci[i] = means[i] + np.array([-s[i] *1.96/np.sqrt(n), s[i]*1.96/np.sqrt(n)])    \n",
    "\n",
    "out1 = ci[:,0] > tm                                   # CI that do not contain the \"true\" mean\n",
    "out2 = ci[:,1] < tm\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "ind = np.arange(1, N_test+1)\n",
    "ax.axhline(y = tm, \n",
    "           xmin = 0, \n",
    "           xmax = N_test+1, \n",
    "           color = [0, 0, 0])\n",
    "ci = np.transpose(ci)\n",
    "ax.plot([ind,ind], \n",
    "        ci, \n",
    "        color = '0.75', \n",
    "        marker = '_', \n",
    "        ms = 0, \n",
    "        linewidth = 3)\n",
    "ax.plot([ind[out1],ind[out1]], \n",
    "        ci[:, out1], \n",
    "        color = [1, 0, 0, 0.8], \n",
    "        marker = '_', \n",
    "        ms = 0, \n",
    "        linewidth = 3)\n",
    "ax.plot([ind[out2],ind[out2]], \n",
    "        ci[:, out2], \n",
    "        color = [1, 0, 0, 0.8], \n",
    "        marker = '_',\n",
    "        ms = 0, \n",
    "        linewidth = 3)\n",
    "ax.plot(ind, \n",
    "        means, \n",
    "        color = [0, .8, .2, .8], \n",
    "        marker = '.',\n",
    "        ms = 10, \n",
    "        linestyle = '')\n",
    "ax.set_ylabel(\"Confidence interval for the samples' mean estimate\",\n",
    "              fontsize = 12)\n",
    "ax.set_xlabel('Samples (with %d observations). '  %n, \n",
    "              fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab75238",
   "metadata": {},
   "source": [
    "We cannot say, for any particular sample, that the 95% confidence interval has a 95% chance of containing the true value.  It may be that the particular sample is really skewed.\n",
    "\n",
    "But what we can say is _in 95% of the cases when we pick a sample, then generate the 95% confidence interval from this sample, then the true value is within that interval 95% of the time!_\n",
    "\n",
    "So 95% of the time we capture the true value 95% of the time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4208eeaf",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "One statistical proposition about a population is to give a measure of the variability of an estimate.\n",
    "\n",
    "Another type of proposition would be _hypothesis testing_, based on the concept of _statistical significance_.\n",
    "\n",
    "Suppose we had done a deeper analysis of traffic accidents in Barcelona and discovered a different value, perhaps a different mean number of accidents, for the years 2010 and 2013.\n",
    "\n",
    "* One possibility is that the difference is just because of chance.  There is variability is both of the estimates, so maybe the underlying parameter has not changed, but just that the two particular samples happened to be different.  This is similar to the differences we discovered when we were using samples of our one dataset.  In essence, the two years are two different samples of the same population.\n",
    "\n",
    "* Another possibility is that there was actually a change to the underlying parameter.  In essence, the two different years really were two separate scenarios, and consequently our estimate changed.  How might the parameter have changed?  Any number of reasons.  More people moved to the city.  The road conditions were deteriorating.  Due to social unrest, people are driving more aggressively.  Perhaps the new cell phone fad took over and more people are texting and driving.  What ever the reason, because the underlying parameter really changed, we can consider the two years as being separate populations.\n",
    "\n",
    "The relevant question is: _Are the observed effects real or not?_\n",
    "\n",
    "Or, more formally: _Were the observed effects statistically significant?_\n",
    "\n",
    "The process of determining the statistical significance of an effect is called _hypothesis testing_.  This process starts by simplifying the options into two competing hypotheses:\n",
    "\n",
    "* $ H_0 $: The mean number of daily traffic accidents is the same in 2010 and 2013, there is only one population, one true mean, and 2010 and 2013 are just different samples from the same population.\n",
    "\n",
    "* $ H_A $: The mean number of daily traffic accidents in 2010 and 2013 is different, these are two samples from two different populations.\n",
    "\n",
    "We call $ H_0 $ the _null hypothesis_ and it represents the _skeptical_ point of view: The effect we have observed is due to chance.  $ H_A $ is the _alternative hypothesis_ and it represents the point of view that the effect is real.\n",
    "\n",
    "The general rule of frequentist hypothesis testing is that we will not _discard_ $ H_0 $, and hence we will not consider $ H_A $, unless the observed effect is _implausible_ under $ H_0 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26807d2",
   "metadata": {},
   "source": [
    "## Testing Hypothesis Using Confidence Intervals\n",
    "\n",
    "We can use _confidence intervals_ to measure the _plausibility_ of a hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f807b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ACCIDENTS_GU_BCN_2010.csv\", encoding='latin-1')\n",
    "#Create a new column which is the date\n",
    "data['Date'] = data['Dia de mes'].apply(lambda x : str(x)) + '-' +  \\\n",
    "               data['Mes de any'].apply(lambda x : str(x))\n",
    "data2 = data['Date']\n",
    "counts2010 =data['Date'].value_counts()\n",
    "print(f'2010: Mean {counts2010.mean():.4f}')\n",
    "\n",
    "data = pd.read_csv(\"ACCIDENTS_GU_BCN_2013.csv\", encoding='latin-1')\n",
    "#Create a new column which is the date\n",
    "data['Date'] = data['Dia de mes'].apply(lambda x : str(x)) + '-' +  \\\n",
    "               data['Mes de any'].apply(lambda x : str(x))\n",
    "data2 = data['Date']\n",
    "counts2013 = data['Date'].value_counts()\n",
    "print(f'2013: Mean {counts2013.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a454a",
   "metadata": {},
   "source": [
    "This preliminary test suggests that in 2013 the mean rate of traffic accidents was higher than in 2010.  But is this effect statistically significant?\n",
    "\n",
    "Earlier we had built a 95% confidence interval for the 2013 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Confidence interval: {confidenceInterval(accidents, 95)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49218f2e",
   "metadata": {},
   "source": [
    "We can see that the 2010 accident rate estimate does not fall in the range of plausible values for 2013.  We can therefore say that the alternative hypothesis cannot be discarded.\n",
    "\n",
    "## Interpreting CI Tests\n",
    "\n",
    "Hypothesis testing is built around rejecting or failing to reject the null hypothesis.  We do not reject $ H_0 $ unless there is strong evidence against it.  But what does strong evidence mean?\n",
    "\n",
    "As a general rule of thumb, for those cases where the null hypothesis is actually true, we do not want to incorrectly reject $ H_0 $ more than 5% of the time.  this corresponds to a _significance level_ of $ \\alpha = 0.05 $. In this case, the correct interpretation of our test is as follows.\n",
    "\n",
    "If the value lies outside of the 95% confidence interval, then we would make an error to reject the null hypothesis only 5% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11574840",
   "metadata": {},
   "source": [
    "## Testing Hypotheses Using _p_-Values\n",
    "\n",
    "This approach is a more advanced notion of _statistical significance_.  We calculate _P_, the probability that the observed measurement would occur if the _null hypothesis_ was true.  This probability is called the _p-value_.\n",
    "\n",
    "Usually, if _P_ is less than 0.05 (the chance of a fluke is less than 5%), the result is declared _statistically significant_.\n",
    "\n",
    "Another way to say this is, \"_Given a sample and an apparent effect, what is the probability of seeing such an effect by chance?_\".\n",
    "\n",
    "Here is how we answer this question:\n",
    "\n",
    "* The first step is to quantify the size of the apparent effect by choosing a test statistic.  In our case, the apparent effect is a difference in accident rates, so the test statistic would be __difference in means between the two periods__.\n",
    "\n",
    "* The second step is to define a _null hypothesis_, which is a model of the system based on the assumption that the apparent effect is not real.  In our case, the null hypothesis is that there is no difference between the two periods.\n",
    "\n",
    "* The third step is to compute a _p-value_, which is the probability of seeing the apparent effect if the null hypothesis is true.  In our case, we would compute the difference in means, then compute the probability of seeing a difference as big, or bigger uner the null hypothesis.\n",
    "\n",
    "* The last step is to _interpret the result_.  If the _p_value_ is low, the effect is said to be _statistically significant_, which means that it is unlikely to have occurred by chance.\n",
    "\n",
    "Let's test this out for our case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e94093",
   "metadata": {},
   "outputs": [],
   "source": [
    "n10 = len(counts2010)\n",
    "n13 = len(counts2013)\n",
    "m10 = counts2010.mean()\n",
    "m13 = counts2013.mean()\n",
    "p = m13 - m10\n",
    "print(f'size of 2010: {n10}, size of 2013: {n13}')\n",
    "print(f'mean of 2010: {m10:.4f}, mean of 2013: {m13:.4f}')\n",
    "print(f'mean difference: {p:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea390ba4",
   "metadata": {},
   "source": [
    "To approximate the _p-value_, we can do the following:\n",
    "\n",
    "* Pool the two input sets, each of size _n_, to form one mixed set, of size _2n_.  We pool the two sets, because under the _null hypothesis_, both sets are samples from the same population, so mixing them simply gives us one sample, of twice the size, that should be 'just as valid' as the two original samples.\n",
    "\n",
    "* Generate a large number of pairs of samples $ \\alpha $ and $ \\beta $ from this mixed set, the size of each sample to be _n_.  We then compute the difference of the means of these two sets.  Note that if the _null hypothesis_ is true, then each iteration should be equivalent to our two original samples (one from 2010 and one from 2013).  In both cases, we had a population from which we extracted two samples, then took the means and computed the differences.\n",
    "\n",
    "* We then count how many of these iterations had values that were larger than the original difference we computed.  If the _null hypothesis_ were true, then our original difference should be 'just like any of the other differences'.  However, if there are very few iterations that had a larger difference, we then conclude that it is unlikely that the two original sets were samples from the same population, they most likely actually came from different populations.\n",
    "\n",
    "Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c825f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling distributions\n",
    "pool = np.concatenate([counts2010, counts2013])\n",
    "np.random.shuffle(pool)\n",
    "\n",
    "# Sample generation\n",
    "# n13 is the size of the 2013 data, from earlier cell\n",
    "N = 10000 # Number of samples\n",
    "diff = [0] * N\n",
    "for i in range(N):\n",
    "    p1 = [random.choice(pool) for _ in range(n13)]\n",
    "    p2 = [random.choice(pool) for _ in range(n13)]\n",
    "    diff[i] = np.mean(p1) - np.mean(p2)\n",
    "\n",
    "# Counting differences larger than the observed one\n",
    "# p is the mean of the comparison between 2013 and 2010, from earlier cell\n",
    "diff2 = pd.DataFrame(diff, columns=['data'])\n",
    "diff3 = diff2[diff2.data > p]\n",
    "p_val = diff3.size/float(diff2.size)\n",
    "print(f'p-value (simulation) = {p_val}')\n",
    "print(f'. (as a percent: {100*p_val}%)')\n",
    "print(f'Difference = {p}')\n",
    "if (p_val < 0.05):\n",
    "    print('The effect is likely')\n",
    "else:\n",
    "    print('The effect is not likely')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7169df0",
   "metadata": {},
   "source": [
    "## Interpreting P-Values\n",
    "\n",
    "A _p_-value is the probability of an an observed (or more extreme) result arising only from chance.\n",
    "\n",
    "If _P_ is less than 0.05, there are two possible conclusions:\n",
    "\n",
    "* There is a real effect, or\n",
    "\n",
    "* The result is an improbable fluke.\n",
    "\n",
    "Let is define a little notation:\n",
    "\n",
    "* _P_: \"The probability of\"\n",
    "\n",
    "* _E_: \"An Effect\", or observation\n",
    "\n",
    "* _H_: \"An Hypothesis\"\n",
    "\n",
    "So _P(E|H)_ means \"the probability of seeing the effect _E_ if the hypothesis _H_ is true\".\n",
    "\n",
    "Conversely, _P(H|E)_ means \"the probability of hypothesis _H_ being true if we observe effect _E_\".\n",
    "\n",
    "These are two different things!  The _p_-value is _P(E|H)_.  So if the _p_-value is less than 0.05, this means that there is only a 5% chance of observing _E_ if the _null hypothesis H_ is true.  The incorrect interpretation is that there is only a 5% chance of the hypothesis _H_ being true if we observe effect _E_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf2911",
   "metadata": {},
   "source": [
    "## But is the Effect _E_ Real?\n",
    "\n",
    "We have not yet answered this question!\n",
    "\n",
    "We have defined a null hypothesis $ H_0 $ (the effect is not real), and we have computed the probability of observing the effect under the null hypothesis, which is $ P ( E | H_0 ) $.\n",
    "\n",
    "We have stated that from a frequentist point of view, we cannot consider $ H_A $ unless $ P ( E | H_0 ) $ is less than a particular arbitrary value.\n",
    "\n",
    "But the real answer to this question must be based on comparing $ P ( H_0 | E ) $ to $ P ( H_A | E ) $.\n",
    "\n",
    "No matter how much data you have, you will still depend on intuition to decide how to interpret, explain, and use that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907aa1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
