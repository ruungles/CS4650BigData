{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45804383",
   "metadata": {},
   "source": [
    "# Topic 12: Descriptive Analytics\n",
    "\n",
    "_Descriptive Analytics_ attempts to describe or understand a dataset.  It does not attempt to determine the merits of a hypothesis, nor does it try to infer characteristics of the _population_.  Although it seems that the examples in the book _do_ attempt to draw some conclusions about the population!\n",
    "\n",
    "Descriptive Analytics is based on two main concepts:\n",
    "\n",
    "* A _population_ is a collection of objects about which information is sought;\n",
    "\n",
    "* A _sample_ is a part of the population that is observed.\n",
    "\n",
    "The assumption is that the data collected from the sample can infer what what we would find if we could collect data from the whole population.\n",
    "\n",
    "The typical flow is:\n",
    "\n",
    "* Data Preparation, where we collect the data and format the data so it is appropriate for analysis.  This usually involves obtaining the data, parsing the data, cleaning the data, and possibly build convenient data structures for storing the data.\n",
    "\n",
    "* Descriptive Statistics, where we generate different statistics to describe and summarize the data concisely and evaluate different ways to visualize them.  There is usually a lot of exploration in this phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da876e",
   "metadata": {},
   "source": [
    "## Setting up Notebook\n",
    "\n",
    "We typically build a new project, then set up the environment for the project, installing the tools and packages we will need.  For this lecture, we will use Jupyter Notebook, Pandas, Numpy, and MatPlotLib.  At the start of the notebook, we import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7eae4d",
   "metadata": {},
   "source": [
    "## Example Data Set\n",
    "\n",
    "For this lecture, we will consider a dataset that contains employement information of about 32,000 adults.  The book fetched this data from the UCI Machine Learning Repository.  The data contains the following parameters:\n",
    "\n",
    "* Age\n",
    "* Sex\n",
    "* Marital Status\n",
    "* Country\n",
    "* Income (a boolean indicating whether the person makes more than $50K/year.\n",
    "* Education (highest level of education achieved\n",
    "* several additional values\n",
    "\n",
    "The question the book seeks to answer is \"Are men more likely to become high-income professionals than women?\"\n",
    "\n",
    "I've downloaded the file, it is included in the 'extra files' for Topic 12, so you can download the data, and this Notebook, so you can run this on your own computer.\n",
    "\n",
    "The following cell will read the data into an array, called 'data'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('adult.data', 'r')\n",
    "\n",
    "def chr_int(a):\n",
    "    if a.isdigit(): return int(a)\n",
    "    else: return 0\n",
    "\n",
    "data = []\n",
    "for line in file:\n",
    "    data1 = line.split(', ')\n",
    "    if len(data1) == 15:\n",
    "        data.append([chr_int(data1[0]), data1[1],\n",
    "                    chr_int(data1[2]), data1[3],\n",
    "                    chr_int(data1[4]), data1[5],\n",
    "                    data1[6], data1[7], data1[8],\n",
    "                    data1[9], chr_int(data1[10]),\n",
    "                    chr_int(data1[11]), chr_int(data1[12]),\n",
    "                    data1[13], data1[14]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2e357",
   "metadata": {},
   "source": [
    "The data is in a CSV (comma separated values) file, which is a text file.  Each line of the file consists of a new record in the dataset.  The values are separated by commas (and a trailing space).  There are 15 values on each line.\n",
    "\n",
    "The code reads the file, one line at a time.  The line is then split by ', ', so the line is divided into an array of tokens.  The code verifies that the line has 15 tokens.\n",
    "\n",
    "The code then creates a new array containing the values, appending this array to the data array.  However, many of the columns contain numeric information, and it would be nice to have these values represented by integers in the program.  So the 'chr_int' function is provided, which will convert a string containing an integer into an integer.  You can see which columns are given this conversion.\n",
    "\n",
    "The following will print one line of the data (from 1 inclusive to 2 exclusive!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d45a8",
   "metadata": {},
   "source": [
    "Recalling that Python arrays are not very efficient, we will construct a Pandas DataFrame with this data.  To do this, we need to provide names for each of the columns.  Looking at the documentation for the dataset, the book decided upon the following names for each column.  These names are stored in an array, then the DataFrame is built.  Finally we 'print' the DataFrame, which will show the first few lines and the last few lines of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef82ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['age', 'type_employer', 'fnlwgt', 'education', 'education_num', 'marital', 'occupation',\n",
    "           'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hr_per_week', 'country', 'income']\n",
    "\n",
    "df = pd.DataFrame(data, columns = colnames)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae37cff",
   "metadata": {},
   "source": [
    "They next wanted to do a little exploratory investigation of the data.  They wanted to see how many people were from each country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby('country').size()\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2cbf4",
   "metadata": {},
   "source": [
    "While we can see that there were many countries represented, we could also see that a very large percentage of the values came from the United States.\n",
    "\n",
    "To begin the investigation, they divided the complete dataset into two subsets, the males and the females.  We will still have the original dataset in the 'df' DataFrame, but now we also have a DataFrame containing only the men, and another Dataframe containing only the women.\n",
    "\n",
    "I was curious, I wanted to see how evenly these two groups were represented, so I asked for the size of the groups.  One quick way to see the size is to ask for the 'shape'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1965c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = df[df.sex == 'Male']\n",
    "female = df[df.sex == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "female.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb339a17",
   "metadata": {},
   "source": [
    "Interesting, there are about twice as many men in the study as women.  We don't yet know how this might influence the outcome, but it is interesting to note.\n",
    "\n",
    "The book went on to further divide the dataset.  They do these divisions so that it is easier later to run analytics on a particular group.  We don't have to do the filtering as part of the analytics, we just pick the subset to use!\n",
    "\n",
    "The book built new DataFrames for males with high income and females with high income.  I just went crazy and made many DataFrames: all people with high income, all people with low income, males with high, males with low, females with high and females with low.\n",
    "\n",
    "By the way, there is that one field indicating whether the person has an income greater than 50K or not.  So we don't have anymore granularity than that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3da4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_high = df[df.income == '>50K\\n']\n",
    "all_low = df[df.income != '>50K\\n']\n",
    "male_high = male[male.income == '>50K\\n']\n",
    "male_low = male[male.income != '>50K\\n']\n",
    "female_high = female[female.income == '>50K\\n']\n",
    "female_low = female[female.income != '>50K\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0733c9",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "We will perform a number of analyses on the sample data (this is sample data because we only have 32,000 entries, we didn't get an entry from _everybody_).  Each analysis will tell us a little information about the people in the sample.  The assumption is that these people _represent_ the whole population, so what information we glean here may approximately apply to the whole population as well.\n",
    "\n",
    "In many cases, we are not looking at one particular overall result, but rather a _distribution_.  For example, in a bit we will be drawing a chart that shows how many people in the sample are of each age.  This chart will show the distribution of people among the ages.  This _sample distribution_ should give us an idea of what the _population distribution_ would be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c685a",
   "metadata": {},
   "source": [
    "## Summarizing the Data\n",
    "\n",
    "For the first example, they looked at the proportion of high-income people in the database.\n",
    "\n",
    "* For all of the samples, what percentage had high-income?\n",
    "\n",
    "* For just the men, what percentage had high-income?\n",
    "\n",
    "* For just the women, what percentage had high-income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rate(label, subset, set):\n",
    "    print(f'The rate of {label} is: {int(len(subset)/float(len(set))*100)}%.')\n",
    "    \n",
    "print_rate('people with high income', all_high, df)\n",
    "print_rate('men with high income', male_high, male)\n",
    "print_rate('women with high income', female_high, female)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14e565",
   "metadata": {},
   "source": [
    "It is difficult to make strong convictions based on these preliminary results.  However, it does appear that the data shows that men are more likely to have a high-income than women.  But we will dig a bit deeper.\n",
    "\n",
    "*__Aside__*\n",
    "\n",
    "For this, and several of the upcoming cells, I changed their code a bit.  They did not define a function, but rather wrote out the formula for each set.  So they did a lot of writing!  But remember the _DRY_ principle: _Don't Repeat Yourself_.  By writing a function, I only had to write the formula one time, but then I could apply it many times!\n",
    "\n",
    "In addition, if I wanted to change the formula a bit, maybe fix a bug, I would only have to change one version, rather than the old way where I would have to make the same fix to all three places where they used the formula.\n",
    "\n",
    "The other thing I did was use the Python 'f-strings'.  This is a string with an 'f' prefix.  Within that string, any characters within {..} are Python code, such as a variable reference or an equation.\n",
    "\n",
    "In future formulas, I will also add precision indicators, to truncate decimal values to just a couple of places to the right of the decimal point.  Its easier doing this once rather than many times.\n",
    "\n",
    "*__Back to the book__*\n",
    "\n",
    "## Sample Mean\n",
    "\n",
    "What do I mean about 'mean'?  Do I think you shouldn't be kind?\n",
    "\n",
    "One of the basic statistics about some data is to compute the _mean_.  The mean is simple the sum of all of the values divided by the number of values.\n",
    "\n",
    "$$ \\mu = \\frac{1}{n} \\sum_{i = 1}^{n} x_i $$\n",
    "\n",
    "Many times we refer to this as the _average_, and in general usage, that is correct.  However, in statistics, 'average' is not strictly defined, and can mean several different values.  To avoid ambiguity, we will use the term 'mean'.\n",
    "\n",
    "Pandas has a built-in function that computes the mean of a series.  In the following code, we use this function to compute the value.  Furthermore, in printing the value, we control the number of digits to be displayed afer decimal point.  The book did not do this, so the numbers printed with 12 digits, which I think is a bit pointless!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbcc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_avg_age(label, set):\n",
    "    print(f'The average age of {label} is: {set.age.mean():.2f}')\n",
    "\n",
    "print_avg_age(\"men\", male);\n",
    "print_avg_age(\"women\", female);\n",
    "print_avg_age(\"high-income men\", male_high);\n",
    "print_avg_age(\"high-income women\", female_high);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eae057",
   "metadata": {},
   "source": [
    "## Sample Variance (Standard Deviation)\n",
    "\n",
    "While the mean is useful, it can be augmented by another value, the _standard deviation_.  This tells us how 'spread out' the values are.  If the standard deviation is small, it means that all the values are fairly close to the mean.  But if the standard deviation is large, some of the values might be quite a bit further from the mean.\n",
    "\n",
    "The formula for the variance is:\n",
    "\n",
    "$$ \\sigma^2 = \\frac{1}{n} \\sum_{i} (x_i - \\mu)^2 $$\n",
    "\n",
    "The standard deviation is simply the square root of the variance.\n",
    "\n",
    "The variance is hard to interpret, because the units are compound.  For example, if we are talking about ages, the variance is in terms of years squared.  However, the standard deviation is in units of years, so this value is much easier to understand!  Consequently, while we can look at the variance, more often we will use the standard deviation.\n",
    "\n",
    "And yes, Pandas has methods for computing the variance (.var()) and standard deviation (.std()) of series, as we can see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3eeb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(label, set):\n",
    "    print(f'Statistics of age for {label}: mu: {set.age.mean():.2f}, var: {set.age.var():.2f}, std: {set.age.std():.2f}')\n",
    "    \n",
    "print_stats('men', male)\n",
    "print_stats('women', female)\n",
    "print_stats('high-income men', male_high)\n",
    "print_stats('high-income women', female_high)\n",
    "print_stats('low-income men', male_low)\n",
    "print_stats('low-income women', female_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce19fec",
   "metadata": {},
   "source": [
    "About 68% of the values are within one standard deviation of the mean.\n",
    "\n",
    "About 95% are within two standard deviations.\n",
    "\n",
    "About 99.7% are within three standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d3e84",
   "metadata": {},
   "source": [
    "## Sample Median\n",
    "\n",
    "The mean and the standard deviation are good descriptors of the data, but they have an important drawback: what will happen if there is an erroneous value in the dataset that is very different from the rest?  A value that is significantly different from the bulk of the data is called an _outlier_.\n",
    "\n",
    "Consider, for example, if a Series contained the number of hours worked per week, which normally would be in the range between 20 and 80; but what if one value, by mistake was 1000?  In this case, the mean would be dramatically shifted toward the outlier.\n",
    "\n",
    "One solution to this drawback is offered by the statistical _median_, $ \\mu_{12} $, which gives the middle value of the sample.  All of the values in the Series would be sorted, and the median is the one that is in the middle of the list.\n",
    "\n",
    "The median is much more robust in the face of outliers.\n",
    "\n",
    "Yes, there is a method of a series which returns the median value, as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a90134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_median(label, set1, set2):\n",
    "    print(f'Median age per {label}: {set1.age.median()} and {set2.age.median()}')\n",
    "    \n",
    "print_median('men and women', male, female)\n",
    "print_median('men and women with high-income', male_high, female_high)\n",
    "print_median('men and women with low-income', male_low, female_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4020f5b",
   "metadata": {},
   "source": [
    "## Quartiles and Percentiles\n",
    "\n",
    "We can go one step further with medians.  Considering the median, 50% of the values are less than the median (and 50% are more).  The median is also called $ Q_2 $.\n",
    "\n",
    "We can also compute the value for which 25% of the values are less.  This value is denoted $ Q_1 $.\n",
    "\n",
    "A third value, at the 75% mark, is called $ Q_3 $.  Together, these values divide the set into four parts of equal size (plus or minus 1).  These are called _quartiles_.\n",
    "\n",
    "A typical analysis of a Series would be to report the smallest value ($ x_{min} $), $ Q_1 $, $ Q_2 $, $ Q_3 $, and $ x_{max} $ (the largest value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5709d",
   "metadata": {},
   "source": [
    "## Data Distributions\n",
    "\n",
    "Summarizing data by looking at the mean, median, and variance is useful, but can also be dangerous.  Sometimes widely differing datasets might have very similar values for these statistics.\n",
    "\n",
    "A very valuable tool when analyzing the data is to visually inspect the data, not as numbers, but through charts and graphs.\n",
    "\n",
    "A _data distribution_ illustrates how often each value appears, giving the value's _frequency_.  The most common representation of a distribution is a _histogram_, a bar chart where the height of each bar shows the frequency of the associated value.\n",
    "\n",
    "The following diagram shows the distribution of ages in the complete dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b52bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.hist(histtype = 'stepfilled', bins = 40)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title('Ages of workers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea05fb8",
   "metadata": {},
   "source": [
    "Recall that _df_ is our complete dataset, and _age_ is the column that gives the person's age.  Typing _df.age_ returns a Series containing these ages.\n",
    "\n",
    "The _hist()_ method will divide the values in the Series into bins, then count the number of entries in each bin.  It then builds the chart.  This actually builds a chart in the _plt_ (MatPlotLib), which is drawn as part of the output of the cell.\n",
    "\n",
    "Note that we added some extra calls to _plt_, indicating the strings to use to label the two axes of the chart and also to give a title for the chart.\n",
    "\n",
    "We can actually plot two charts superimposed.  In the following diagram, we show the histograms of both the men and the women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "male.age.hist(histtype = 'stepfilled', alpha = 0.5, bins = 20, label='Men')\n",
    "female.age.hist(histtype = 'stepfilled', alpha = 0.5, bins = 20, label='Women')\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.title('Ages of working men and women')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9b20b",
   "metadata": {},
   "source": [
    "Before we look at the data itself, let's spend a few minutes looking at some of the options that are available with histograms and the _plt_ tool.  This introduction will be brief, but will hopefully give you some insights into how the system can be used.\n",
    "\n",
    "Note that we simply generate two (or more) histograms; they by default become part of the same diagram.\n",
    "\n",
    "Also note in each of the histograms, we can give a Label.  This Label value is printed in the legend.\n",
    "\n",
    "One of the calls to _plt_ indicates where the legend should be drawn.  There are several options available.  Pick a corner of the diagram that won't obscure the chart!\n",
    "\n",
    "There are many additional options available, which allow you to do fine positioning of the elements.\n",
    "\n",
    "The observant reader will see that we also assigned _alpha_ values to the two histograms.  Let's discover what these are for, first by removing those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "male.age.hist(histtype = 'stepfilled', bins = 20, label='Men')\n",
    "female.age.hist(histtype = 'stepfilled', bins = 20, label='Women')\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.title('Ages of working men and women')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d42c05",
   "metadata": {},
   "source": [
    "The colors are a little more intense.  Before, with alpha setting, they were half-way transparent, so some of the underlying white showed through.  Without the alpha, the full-intensity colors are drawn.\n",
    "\n",
    "Look what happens if we switch the order of the male and female plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8bc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "female.age.hist(histtype = 'stepfilled', bins = 20, label='Women')\n",
    "male.age.hist(histtype = 'stepfilled', bins = 20, label='Men')\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.title('Ages of working men and women')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b81556",
   "metadata": {},
   "source": [
    "What happened to the women?  The plot legend says they are still there, but they are gone!\n",
    "\n",
    "The problem is that the woman's chart is completely covered by the men's chart.  We drew the women's graph first, then we overwrote this with the men's graph.  Because all of the colors we are drawing are solid colors, they completely block anything under them.  \n",
    "\n",
    "Now look what happens if we put the alpha back (although we only have to add the alpha to the second and any later plots):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60308178",
   "metadata": {},
   "outputs": [],
   "source": [
    "female.age.hist(histtype = 'stepfilled', bins = 20, label='Women')\n",
    "male.age.hist(histtype = 'stepfilled', bins = 20, alpha = 0.5, label='Men')\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.title('Ages of working men and women')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74235d8",
   "metadata": {},
   "source": [
    "Now we can see both charts again.  The women graph, drawn first, is with solid colors.  The men graph, drawn second, has half-way transparent coloring (alpha = 0.5), so the color is partially transparent.  The women graph can show through.\n",
    "\n",
    "An alpha value of 0.0 means that the color is completely transparent, so the chart drawn with this color would be invisible.  An alpha value of 1.0 is completely solid.  You can experiment with the various alpha values to get the graph appearing as you desire.\n",
    "\n",
    "We can also draw a non-filled graph using 'step' rather than 'stepfilled'.  We might want to keep the alpha, just in case there is a bin where they have the same height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d033e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "female.age.hist(histtype = 'step', bins = 20, label='Women')\n",
    "male.age.hist(histtype = 'step', bins = 20, alpha = 0.5, label='Men')\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.title('Ages of working men and women')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0085ad1",
   "metadata": {},
   "source": [
    "These charts give us some idea about the data.  \n",
    "\n",
    "## Normalizing Charts: Probability Mass Functions\n",
    "\n",
    "One thing that is pretty clear is that there are more men datapoints than women datapoints.  And these differences in the dataset sizes may obscure some important analysis results.\n",
    "\n",
    "We can _normalize_ the charts.  \n",
    "\n",
    "* When the data is normalized, the numbers are scaled so that the area under the curve is equal to '1'.  \n",
    "\n",
    "* Another way to look at this, the values are all divided by the sum of all the values.\n",
    "\n",
    "* A normalized graph is similar to looking at _percentages_ rather than actual values.\n",
    "\n",
    "This is how the data looks when it is normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22290af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "male.age.hist(density = True, histtype = 'stepfilled', bins = 20, alpha = 0.5, label='Men')\n",
    "female.age.hist(density = True, histtype = 'stepfilled', bins = 20, alpha = 0.5, label='Women')\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.title('Probability Mass Function of Ages')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76d9a6",
   "metadata": {},
   "source": [
    "We can see from this chart that of the women who responded to the study, a higher percentage of them were younger, and for men, a higher percentage were older.  And around age 30 was the turning point.\n",
    "\n",
    "A normalized histogram is called a _Probability Mass Function_.\n",
    "\n",
    "## Cumulative Distribution Function\n",
    "\n",
    "Another way to look at this data is a _Cumulative Distribution Function_, which basically just sums up all of the values 'to the left' of your current position.  So the first bar just has its height.  The height of the second bar reflects its value plus the value of the first column.  The height of the third column is the sum of the values for the first three columns, and so forth.  With this graph, the height at coordinate _x_ represents the probability that the an element will have a value less than or equal to _x_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "male.age.hist(density = True, histtype = 'step', bins = 20, alpha = 0.5, label='Men', cumulative = True)\n",
    "female.age.hist(density = True, histtype = 'step', bins = 20, alpha = 0.5, label='Women', cumulative = True)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.title('Cumulative Distribution Function of Ages')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e2ead",
   "metadata": {},
   "source": [
    "This graph shows that for most ages, there is a higher percentage of women who reported at or below that age then men who reported.  Conversely, men tended to respond to this study at a greater age than women."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f7859",
   "metadata": {},
   "source": [
    "## Digression: Age vs Salary\n",
    "\n",
    "At this point, a new thought occurred to me: How does higher salary correlate to age?  The discussion from the book so far was seeking to find a correlation between sex and salary, but I was curious about the correlation between age and salary.\n",
    "\n",
    "To do this, I wanted to draw a graph that showed, for any age group, what percentage of responders had high income?\n",
    "So I need a way to make a DataFrame where the indicies are the ages and the values are the percentage of entries in that age category that are high-income.\n",
    "\n",
    "We can get Pandas to group data by age, and it can then aggregate the information.\n",
    "\n",
    "In the following cell, we group the data by age, then print out one of the resulting groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df.groupby('age')\n",
    "group.get_group(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0738042",
   "metadata": {},
   "source": [
    "We can apply an aggregation function that runs over all of the entries in a group, then returns a single value for the group.  The aggregation has to be performed on a numeric column, so why don't we use the _hr_per_week_ and look at the average (mean) value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = group.aggregate(np.mean)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168be77",
   "metadata": {},
   "source": [
    "The aggregation functions are things like min, max, sum, average, count, and so on.  But these all work on numbers, and our high-income indication is a column that has text values.\n",
    "\n",
    "So the first step will be to add a new column to the data that has a '1' for high-income and a '0' for low income.\n",
    "\n",
    "Once we have numbers, then what aggregation do we use to determine the percentage of highs?  It took a while, but then became clear, this is simply the mean value of 'high_income' for the group.  Then, to really make this a percentage, scale the number by 100.\n",
    "\n",
    "_Alternatively, rather than using values of 0 and 1 in the high_income column, then later scale by 100, we can just use values of 0 and 100 in that column, which is what I did._\n",
    "\n",
    "Another issue is that we don't want to do this for each age, but each 'bucket of age'.  In the bar graph, we used 20 bins, so about 5 years per bin.  So let's make another column, the 'age_bin' column, where all ages from 20-24 will use value '22'.\n",
    "\n",
    "That's the plan, now to accomplish the plan.\n",
    "\n",
    "To not mess up our main flow, for this digression I will make a copy of the DataFrame, then add a new column to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempset = df.copy()  # copy the data\n",
    "tempset['high_income'] = 100*(tempset.income == '>50K\\n').astype(int)  # make new 'high-income' column\n",
    "tempset['age_bin'] = tempset.age - tempset.age % 5 + 2  # make new 'age-bin' column\n",
    "tempset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d533e",
   "metadata": {},
   "source": [
    "Looking at the right end of the chart, we can see the new columns we added, and we can spot-check to see of the code worked.  It appears to have worked!\n",
    "\n",
    "We can now examine just the _age_bin_ and _high_income_ columns, then group the data by _age_bin_.  This makes a nested set of values where the outer set is the age_bin and the inner set is the _high_income_ values for all of the people in that set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66680fba",
   "metadata": {},
   "source": [
    "We can then call the _mean()_ function on that grouping.  This will collapse the inner sets, giving the mean value of each of those sets!  After doing this grouping, we print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50659ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = tempset[['age_bin', 'high_income']].groupby('age_bin').mean()\n",
    "group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b230c",
   "metadata": {},
   "source": [
    "The first (and last) bins are pretty much outliers, so let's look at a few other bins.\n",
    "\n",
    "* The 22 bin has the value 1.507795, indicating that about 1.5% of the people in the age range from 20 to 24 have high income.\n",
    "\n",
    "* The 52 bin shows that about 41% of the people in the age range 50 to 54 have high income.\n",
    "\n",
    "Looking at the numbers is interesting, and it is important to have this data for when we want to dig deeper, but it is hard to draw conclusions just by seeing the numbers.  So let's draw a plot of this distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a843a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(group)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Percent High-Income\")\n",
    "plt.title('Probability of High-Income by Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31056b1f",
   "metadata": {},
   "source": [
    "Now this is interesting!  It shows that there is a very dramatic correlation between age and high-income!  Below about 20 or 30, there is a low percentage of people having high income, but that the probability is much higher above that.  Which is not surprising.  It takes a while to be promoted, to reach a higher salary.\n",
    "\n",
    "What do we make of the drop in salary as age increases past 55?  We don't really know, we haven't dug deep enough.  Some thoughts come to mind:\n",
    "\n",
    "* People tend to retire around 65, so fewer people are working after that point.\n",
    "\n",
    "* For people with really low salaries, maybe they can't afford to retire?\n",
    "\n",
    "* Maybe the people who worked hard when they were younger, to get the higher salaries, died younger?\n",
    "\n",
    "These ideas may prompt us to pursue new avenues of investigation.\n",
    "\n",
    "Recall from our earlier graph: A higher percentage of women respondents than men respondents were less than 30 years old.  A higher percentage of men respondents than women respondents were more than 30 years old.  \n",
    "\n",
    "This graph shows that there was a higher percentage of respondents with high income above age 30 than below age 30.\n",
    "\n",
    "Combining these two results indicates that maybe the correlation is not between sex and wage but between age and wage.  Something to consider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fe919",
   "metadata": {},
   "source": [
    "## Digression: Education vs Salary\n",
    "\n",
    "Another thought that came to mind: Maybe the salary depends upon the level of education.  Actually, I kind of hope so, because otherwise you will all leave and I will be without a job!\n",
    "\n",
    "For this analysis, we want to group the data by the educational level, then compute statistics and make some charts and graphs.\n",
    "\n",
    "The problem is that if we are grouping by the 'education' field, the groups will come out sorted alphabetically, not sorted by years of education (for example).  But looking at the dataset, we see there is a column labeled 'education_num', and this appears to be numeric and in order, so we will group by that.\n",
    "\n",
    "For this analysis, I will make four Series.  One for Female/High income, and the others are similar.  We take these complete sets, group them by 'education_num', then aggregate each set by asking for the size.  This will give us the count of elements (people) in each of the education_num categories.\n",
    "\n",
    "Finally, we will assemble the four Series into one Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0055c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhe = female_high.groupby('education_num').size()\n",
    "fle = female_low.groupby('education_num').size()\n",
    "mhe = male_high.groupby('education_num').size()\n",
    "mle = male_low.groupby('education_num').size()\n",
    "edu = pd.DataFrame({'FemaleHigh': fhe, 'FemaleLow': fle, 'MaleHigh': mhe, 'MaleLow': mle})\n",
    "edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70abcbbc",
   "metadata": {},
   "source": [
    "While those printouts look interesting, a graph might be a lot more informative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1597ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(edu.FemaleHigh, label = 'Female High')\n",
    "plt.plot(edu.FemaleLow, label = 'Female Low')\n",
    "plt.plot(edu.MaleHigh, label = 'Male High')\n",
    "plt.plot(edu.MaleLow, label = 'Male Low')\n",
    "plt.xlabel(\"Education\")\n",
    "plt.ylabel(\"Number of Entries\")\n",
    "plt.title('Number of People at Each Educational Level')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ed915",
   "metadata": {},
   "source": [
    "This is interesting, we can see some pretty obvious spikes, one around 9 and the other around 13.  We have no idea what these educational levels mean, they are just numbers.  So the first thing we want to do is find out that these education_num values mean.\n",
    "\n",
    "The second thing is that the spikes look very obvious for lower-income males, but not very obvious for high-income females.  The other two groups are in the middle range.  So let's look at this too.\n",
    "\n",
    "First, how are we going to determine the mapping of education_num to education, which is a more meaningful string.  On one hand, we can simply scan through the dataset, looking for sample values, and writing (by hand) a little chart.  But why own a dog, then bark for ourselves?  We have a computer, lets get it to do the work.\n",
    "\n",
    "How will we go about this?\n",
    "\n",
    "Let's make a new DataFrame that just contains the 'education' and 'education_num' values.  This will still have 32,000 entries, but it will only have the two columns we are interested in.\n",
    "\n",
    "We could group this by 'education_num'.  This will give us a group for each numeric value, and within each group will be a set entries, all having the same 'education' string.  We can't do much to aggregate that, since the value is a string.\n",
    "\n",
    "Alternatively, we can group this by 'education'.  This will give us a group for each string value, and within each group will be a set of entries, all having the same 'education_num' value.  We can then aggregate this by using max(), min(), or mean() (since all of the values are the same.\n",
    "\n",
    "The result will be a DataFrame with just 16 entries, each having the 'education' value and its matching 'education_num'.\n",
    "\n",
    "The last thing we need to do is sort the list.  Otherwise it will be sorted alphabetically by 'education' name.  So let's sort by the 'education_num'.  We can then print the resulting chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = df[['education', 'education_num']].groupby('education').max()\n",
    "set1.sort_values(by = 'education_num', ascending = True, inplace = True)\n",
    "set1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae120f9e",
   "metadata": {},
   "source": [
    "Recall that the biggest spike was at 9, which corresponds to high school graduate.  There is a second spike at 13, which is Bachelor's degree.  And actually, there is another spike, greater than the Bachelor's degree, at 10 (some college).  The 10 spike is adjacent to the 9 spike, so it blended in.\n",
    "\n",
    "So we've learned the more popular educational levels, which is probably pretty much what we expect.\n",
    "\n",
    "Our next task is to normalize the data.  This will help pull out the trends.  Right now what overwhelms the report is the sheer number of entries.  But we might not be concerned about the _number of people_ at a certain level, but rather the _percentage of people_ at that level.\n",
    "\n",
    "Also, rather than overwriting our current columns in the DataFrame, we will make new columns.  In the following, we make a new column by taking an old column, dividing each entry by the sum of that column, then multiply by 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu['FHNorm'] = 100 * edu.FemaleHigh / edu.FemaleHigh.sum()\n",
    "edu['FLNorm'] = 100 * edu.FemaleLow / edu.FemaleLow.sum()\n",
    "edu['MHNorm'] = 100 * edu.MaleHigh / edu.MaleHigh.sum()\n",
    "edu['MLNorm'] = 100 * edu.MaleLow / edu.MaleLow.sum()\n",
    "edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6266ed",
   "metadata": {},
   "source": [
    "Now we can plot the new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9dba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(edu.FHNorm, label = 'Female High')\n",
    "plt.plot(edu.FLNorm, label = 'Female Low')\n",
    "plt.plot(edu.MHNorm, label = 'Male High')\n",
    "plt.plot(edu.MLNorm, label = 'Male Low')\n",
    "plt.xlabel(\"Education\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title('Percentage of People at Each Educational Level')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1baace2",
   "metadata": {},
   "source": [
    "Ah, this is very interesting.  We notice that there is not much difference between males and females.\n",
    "\n",
    "However, we see that at the high-school spike and below, there is a higher percentage of low-income people, and from the Bachelor's spike and above, there is a higher percentage of high-income people.\n",
    "\n",
    "This is great news!  It seems like my job is secure, and you will be hanging around!\n",
    "\n",
    "Let's make one more graph!  Earlier we made a graph giving the probability of high-income based on age.  We can reuse and tweek that code to instead graph the probability of high-income based on educational level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = tempset[['education_num', 'high_income']].groupby('education_num').mean()\n",
    "plt.plot(group)\n",
    "plt.xlabel(\"Education Level\")\n",
    "plt.ylabel(\"Percent High-Income\")\n",
    "plt.title('Probability of High-Income by Education')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32388f9f",
   "metadata": {},
   "source": [
    "This should be on Cal Poly's website!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc14b51",
   "metadata": {},
   "source": [
    "## Undigression\n",
    "\n",
    "OK, enough of these side-trips.  Let's return to the book.  There are a few more things to cover in this chapter.\n",
    "\n",
    "And actually, there are some things in the book that I won't cover..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6dc3b",
   "metadata": {},
   "source": [
    "## Outlier Treatment\n",
    "\n",
    "Outliers are data samples with a value that is far from the central tendency.  Perhaps the value is far from the median, or the value is further from the mean than 2 or 3 standard deviations.\n",
    "\n",
    "In this dataset, we have some values at age 17, and some at 90.  These extreme values are probably not representative of the population as a whole, and maybe are a result of data entry errors.  Based on our knowledge of the domain, we may conclude that from the median of 37, we will go down to about 22 and up to about 72 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(set):\n",
    "    return set[(set.age >= 22) & (set.age <= 72)]\n",
    "\n",
    "male_filter = filter_outliers(male)\n",
    "female_filter = filter_outliers(female)\n",
    "male_high_filter = filter_outliers(male_high)\n",
    "female_high_filter = filter_outliers(female_high)\n",
    "male_low_filter = filter_outliers(male_low)\n",
    "female_low_filter = filter_outliers(female_low)\n",
    "all_high_filter = filter_outliers(all_high)\n",
    "all_low_filter = filter_outliers(all_low)\n",
    "df_filter = filter_outliers(df)\n",
    "\n",
    "male_filter.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74294593",
   "metadata": {},
   "source": [
    "We can see in the description of the filtered male data that the minimum age is 22 and the maximum is 72, and that we still have 19,891 entries.  It looks like we have successfully removed the outliers.\n",
    "\n",
    "We can now run the statistic routine that we ran earlier.  In the following, I run the old sets followed by the filtered sets, so we can see how the values may or may not have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rate('men with high income', male_high, male)\n",
    "print_rate('filtered men with high income', male_high_filter, male_filter)\n",
    "print_rate('women with high income', female_high, female)\n",
    "print_rate('filtered women with high income', female_high_filter, female_filter)\n",
    "\n",
    "print_stats('men', male)\n",
    "print_stats('filtered men', male_filter)\n",
    "print_stats('women', female)\n",
    "print_stats('filtered women', female_filter)\n",
    "print_stats('high-income men', male_high)\n",
    "print_stats('filtered high-income men', male_high_filter)\n",
    "print_stats('high-income women', female_high)\n",
    "print_stats('filtered high-income women', female_high_filter)\n",
    "print_stats('low-income men', male_low)\n",
    "print_stats('filtered low-income men', male_low_filter)\n",
    "print_stats('low-income women', female_low)\n",
    "print_stats('filtered low-income women', female_low_filter)\n",
    "\n",
    "print_median('men and women', male, female)\n",
    "print_median('filtered men and women', male_filter, female_filter)\n",
    "print_median('men and women with high-income', male_high, female_high)\n",
    "print_median('filtered men and women with high-income', male_high_filter, female_high_filter)\n",
    "print_median('men and women with low-income', male_low, female_low)\n",
    "print_median('filtered men and women with low-income', male_low_filter, female_low_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0293a49",
   "metadata": {},
   "source": [
    "We see that not of the statistics changed dramatically.  However we see in many of the statistics, comparing males and females got a little closer together.\n",
    "\n",
    "We can plot one of the sets, both with and without the outliers, so get a visual about the number of values that were dropped.  I used one of the smaller sets: With a bigger sets the plots were a lot denser!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13.4, 5))\n",
    "female_high.age.plot(alpha = .25, color = 'blue')\n",
    "female_high_filter.age.plot(alpha = .45, color = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b2cac",
   "metadata": {},
   "source": [
    "## Measuring Asymmetry: Skewness and Pearson's Median Skewness Coefficient\n",
    "\n",
    "Sometimes we want to see if the data is _skewed_.  If a distribution is skewed, the data stretches further from the mean in one direction or the other.  A negative skew means that values below the mean tend to be further from the mean while values above the mean tend to be closer to the mean.\n",
    "\n",
    "The formula for skew is:\n",
    "\n",
    "$$ g_1 = \\frac{1}{n} \\frac{\\sum_{i} (x_i - \\mu^3)}{\\sigma^3} $$\n",
    "\n",
    "If the distribution is normal, the skew would be zero.\n",
    "\n",
    "Note that skewness can be affected by outliers!  A simpler indication of this is to compare the mean and the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8814d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness(x, label):\n",
    "    res = 0\n",
    "    m = x.mean()\n",
    "    s = x.std()\n",
    "    for i in x:\n",
    "        res += (i - m) * (i - m) * (i - m)\n",
    "    res /= (len(x) * s * s * s)\n",
    "    print(f'Skewness of the {label} population = {res}')\n",
    "    \n",
    "skewness(male_high.age, 'male')\n",
    "skewness(male_high_filter.age, 'filtered male')\n",
    "skewness(female_high.age, 'female')\n",
    "skewness(female_high_filter.age, 'filtered female')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2819493",
   "metadata": {},
   "source": [
    "Notice that these are a bit skewed, but that the filtered versions display less skewness.\n",
    "\n",
    "The **Pearson's median skewness coefficient** is a more robust alternative to the skewness coefficient, and is defined as follows:\n",
    "\n",
    "$$ g_p = 3(\\mu - \\mu_{12}) \\sigma $$\n",
    "\n",
    "There are many other definitions of skewness that statisticians use, but we won't discuss them!\n",
    "\n",
    "Here shows the Pearson's coefficient for men and women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73000edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(x, label):\n",
    "    s = 3 * (x.mean() - x.median()) * x.std()\n",
    "    print(f\"Pearson's coefficient of the {label} population = {s}\")\n",
    "    \n",
    "pearson(male_high_filter.age, \"male\")\n",
    "pearson(female_high_filter.age, \"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0e329",
   "metadata": {},
   "source": [
    "The book has several additional methods and statistics that it presents, but we have covered most of the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc378c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
